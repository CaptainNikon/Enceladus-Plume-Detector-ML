{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59088de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 89,790 events from 3 files across volumes ['COCDA_0011', 'COCDA_0012', 'COCDA_0013'].\n",
      "           EVENT_TIME  EVENT_QUALITY  QP_AMPLITUDE  QI_AMPLITUDE  QT_AMPLITUDE\n",
      "0 2005-04-01 00:31:35            NaN           0.0  3.100000e-15  1.100000e-14\n",
      "1 2005-04-01 00:32:59            NaN           0.0  1.400000e-14  0.000000e+00\n",
      "2 2005-04-01 00:45:26            NaN           0.0  0.000000e+00  1.000000e-14\n",
      "3 2005-04-01 00:46:29            NaN           0.0  6.600000e-14  6.300000e-15\n",
      "4 2005-04-01 00:48:06            NaN           0.0  0.000000e+00  5.500000e-15\n"
     ]
    }
   ],
   "source": [
    "'''This script loads datasets issued by the Cassini CDA instrument, assigns labels, handles \n",
    "missing values, and combines the data from multiple volumes into a single Dataframe.'''\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- column positions and their labels according to the LBL-files ---\n",
    "colspecs = [\n",
    "    (0,10), (11,28), (29,43), (44,52), (53,54),\n",
    "    (55,63), (64,65), (66,74), (75,76), (77,85),\n",
    "    (86,87), (88,96), (97,105), (106,114), (115,116),\n",
    "    (117,124), (125,132), (133,139), (140,147),\n",
    "    (148,155), (156,164), (165,171), (172,178),\n",
    "    (179,185), (186,193), (194,201), (202,204),\n",
    "    (205,208), (209,214), (215,219), (220,228),\n",
    "    (229,233), (234,242), (243,251), (252,253)\n",
    "]\n",
    "\n",
    "colnames = [\n",
    "    \"EVENT_ID\",\"EVENT_TIME\",\"EVENT_JULIAN_DATE\",\n",
    "    \"QP_AMPLITUDE\",\"QP_SIGNAL_FLAG\",\"QI_AMPLITUDE\",\"QI_SIGNAL_FLAG\",\n",
    "    \"QT_AMPLITUDE\",\"QT_SIGNAL_FLAG\",\"QC_AMPLITUDE\",\"QC_SIGNAL_FLAG\",\n",
    "    \"QI_RISE_TIME\",\"QT_RISE_TIME\",\"QC_RISE_TIME\",\"TARGET_FLAG\",\n",
    "    \"SPACECRAFT_RA\",\"SPACECRAFT_DEC\",\"SPACECRAFT_SUN_DISTANCE\",\n",
    "    \"SPACECRAFT_SIII_LONG\",\"SPACECRAFT_SIII_LAT\",\"SPACECRAFT_SAT_DIST\",\n",
    "    \"SC_X_VEL\",\"SC_Y_VEL\",\"SC_Z_VEL\",\"DETECTOR_RA\",\"DETECTOR_DEC\",\n",
    "    \"COUNTER_NUMBER\",\"EVENT_QUALITY\",\"PARTICLE_SPEED\",\"PARTICLE_SPEED_FACTOR\",\n",
    "    \"PARTICLE_MASS\",\"PARTICLE_MASS_FACTOR\",\"PARTICLE_CHARGE\",\"PARTICLE_CHARGE_ERROR\",\n",
    "    \"SPECTRUM_FLAG\"\n",
    "]\n",
    "\n",
    "# --- Missing value conventions ---\n",
    "missing_values = {\n",
    "    \"EVENT_ID\": -999999999,\n",
    "    \"EVENT_TIME\": \"9999-999T99:99:99\",\n",
    "    \"EVENT_JULIAN_DATE\": -999999.999999,\n",
    "    \"QP_AMPLITUDE\": -9.9E-99,\n",
    "    \"QI_AMPLITUDE\": -9.9E-99,\n",
    "    \"QT_AMPLITUDE\": -9.9E-99,\n",
    "    \"QC_AMPLITUDE\": -9.9E-99,\n",
    "    \"QI_RISE_TIME\": -9.9E-99,\n",
    "    \"QT_RISE_TIME\": -9.9E-99,\n",
    "    \"QC_RISE_TIME\": -9.9E-99,\n",
    "    \"SPACECRAFT_RA\": -999.99,\n",
    "    \"SPACECRAFT_DEC\": -999.99,\n",
    "    \"SPACECRAFT_SUN_DISTANCE\": 9.9999,\n",
    "    \"SPACECRAFT_SIII_LONG\": -999.99,\n",
    "    \"SPACECRAFT_SIII_LAT\": -999.99,\n",
    "    \"SPACECRAFT_SAT_DIST\": -9999.99,\n",
    "    \"SC_X_VEL\": -99.99,\n",
    "    \"SC_Y_VEL\": -99.99,\n",
    "    \"SC_Z_VEL\": -99.99,\n",
    "    \"DETECTOR_RA\": -999.99,\n",
    "    \"DETECTOR_DEC\": -999.99,\n",
    "    \"COUNTER_NUMBER\": -9,\n",
    "    \"EVENT_QUALITY\": -9,\n",
    "    \"PARTICLE_SPEED\": -99.9,\n",
    "    \"PARTICLE_SPEED_FACTOR\": -9.9,\n",
    "    \"PARTICLE_MASS\": -9.9E-99,\n",
    "    \"PARTICLE_MASS_FACTOR\": -9.9,\n",
    "    \"PARTICLE_CHARGE\": -9.9E-99,\n",
    "    \"PARTICLE_CHARGE_ERROR\": -9.9E-99,\n",
    "    \"SPECTRUM_FLAG\": 9\n",
    "}\n",
    "\n",
    "all_dfs = []\n",
    "all_files = []\n",
    "\n",
    "# --- volumes to load ---\n",
    "volumes = [Path(\"Dataset/COCDA_0011\"),\n",
    "           Path(\"Dataset/COCDA_0012\"),\n",
    "           Path(\"Dataset/COCDA_0013\")]\n",
    "\n",
    "for vol in volumes:\n",
    "    # find the event files\n",
    "    files = sorted(vol.glob(\"DATA/**/CDAEVENTS_*.TAB\"))\n",
    "    if not files:\n",
    "        print(f\"[warning] no event file found in {vol}/DATA\")\n",
    "    all_files.extend(files)\n",
    "\n",
    "    for f in files:\n",
    "        # read\n",
    "        df = pd.read_fwf(\n",
    "            f, colspecs=colspecs, names=colnames,\n",
    "            na_values=missing_values\n",
    "        )\n",
    "        # convert event time (yearâ€“doy format -> datetime)\n",
    "        df[\"EVENT_TIME\"] = pd.to_datetime(\n",
    "            df[\"EVENT_TIME\"], errors=\"coerce\", format=\"%Y-%jT%H:%M:%S\"\n",
    "        )\n",
    "        \n",
    "        df[\"SOURCE_VOLUME\"] = vol.name\n",
    "        df[\"SOURCE_FILE\"] = f.name\n",
    "        all_dfs.append(df)\n",
    "\n",
    "if not all_dfs:\n",
    "    raise RuntimeError(\"No tables were loaded. Check paths or volume names.\")\n",
    "\n",
    "final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "print(f\"Loaded {len(final_df):,} events from {len(all_files)} files \"\n",
    "      f\"across volumes {[v.name for v in volumes]}.\")\n",
    "\n",
    "# --- Check the head ---\n",
    "print(final_df[[\"EVENT_TIME\",\"EVENT_QUALITY\",\"QP_AMPLITUDE\",\"QI_AMPLITUDE\",\"QT_AMPLITUDE\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efab04a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
