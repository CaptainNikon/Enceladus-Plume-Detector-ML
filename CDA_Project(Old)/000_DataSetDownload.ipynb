{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c023ef",
   "metadata": {},
   "source": [
    "## Helper script\n",
    "This is a helper sript defined to find the DOY of each plume flyby to match the Cassini database documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e7b30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a9ea9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E3: Year: 2008 | DOY: 72\n",
      "E4: Year: 2008 | DOY: 224\n",
      "E5: Year: 2008 | DOY: 283\n",
      "E6: Year: 2008 | DOY: 305\n",
      "E7: Year: 2009 | DOY: 306\n",
      "E9: Year: 2010 | DOY: 118\n",
      "E12: Year: 2010 | DOY: 334\n",
      "E13: Year: 2010 | DOY: 355\n",
      "E14: Year: 2011 | DOY: 274\n",
      "E17: Year: 2012 | DOY: 87\n",
      "E18: Year: 2012 | DOY: 105\n",
      "E19: Year: 2012 | DOY: 123\n",
      "E21: Year: 2015 | DOY: 301\n"
     ]
    }
   ],
   "source": [
    "# Get the DOY of all flybys to match the CDA databases to download\n",
    "\n",
    "flybys = [\n",
    "    (\"E3\",  \"2008-03-12 19:06:45\"),\n",
    "    (\"E4\",  \"2008-08-11 21:06:30\"),\n",
    "    (\"E5\",  \"2008-10-09 19:07:00\"),\n",
    "    (\"E6\",  \"2008-10-31 17:15:30\"),\n",
    "    (\"E7\",  \"2009-11-02 07:42:00\"),\n",
    "    (\"E9\",  \"2010-04-28 19:09:30\"),\n",
    "    (\"E12\", \"2010-11-30 12:06:00\"),\n",
    "    (\"E13\", \"2010-12-21 13:11:00\"),\n",
    "    (\"E14\", \"2011-10-01 18:40:00\"),\n",
    "    (\"E17\", \"2012-03-27 18:30:00\"),\n",
    "    (\"E18\", \"2012-04-14 18:08:00\"),\n",
    "    (\"E19\", \"2012-05-02 18:12:00\"),\n",
    "    (\"E21\", \"2015-10-28 15:22:00\"),\n",
    "]\n",
    "\n",
    "\n",
    "for name, date_str in flybys:\n",
    "    dt = pd.to_datetime(date_str)\n",
    "    doy = dt.dayofyear\n",
    "    print(f\"{name}: Year: {dt.year} | DOY: {doy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f5fca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COCDA_0007: 2005-01-01 00:02:42 -> 2005-03-31 23:59:49\n",
      "  No flybys inside COCDA_0007.\n",
      "\n",
      "COCDA_0012: 2005-07-01 00:00:44 -> 2005-07-21 23:58:48\n",
      "  No flybys inside COCDA_0012.\n",
      "\n",
      "COCDA_0045: 2008-03-02 01:01:41 -> 2008-03-31 23:57:25\n",
      "  Flybys inside COCDA_0045: E3 (2008-03-12 19:06:45)\n",
      "\n",
      "COCDA_0050: 2008-08-04 13:36:30 -> 2008-08-26 13:39:19\n",
      "  Flybys inside COCDA_0050: E4 (2008-08-11 21:06:30)\n",
      "\n",
      "COCDA_0052: 2008-10-01 02:00:50 -> 2008-11-01 00:01:49\n",
      "  Flybys inside COCDA_0052: E5 (2008-10-09 19:07:00), E6 (2008-10-31 17:15:30)\n",
      "\n",
      "COCDA_0057: 2009-10-01 00:12:56 -> 2009-12-31 23:54:25\n",
      "  Flybys inside COCDA_0057: E7 (2009-11-02 07:42:00)\n",
      "\n",
      "COCDA_0059: 2010-04-01 00:35:26 -> 2010-06-30 23:35:06\n",
      "  Flybys inside COCDA_0059: E9 (2010-04-28 19:09:30)\n",
      "\n",
      "COCDA_0061: 2010-10-01 03:41:14 -> 2010-12-31 22:29:26\n",
      "  Flybys inside COCDA_0061: E12 (2010-11-30 12:06:00), E13 (2010-12-21 13:11:00)\n",
      "\n",
      "COCDA_0069: 2011-10-01 01:35:37 -> 2011-10-31 22:46:35\n",
      "  Flybys inside COCDA_0069: E14 (2011-10-01 18:40:00)\n",
      "\n",
      "COCDA_0070: 2011-11-01 01:01:30 -> 2011-12-01 23:10:10\n",
      "  No flybys inside COCDA_0070.\n",
      "\n",
      "COCDA_0074: 2012-03-03 01:29:23 -> 2012-03-29 06:58:44\n",
      "  Flybys inside COCDA_0074: E17 (2012-03-27 18:30:00)\n",
      "\n",
      "COCDA_0075: 2012-03-31 21:31:45 -> 2012-04-14 19:26:34\n",
      "  Flybys inside COCDA_0075: E18 (2012-04-14 18:08:00)\n",
      "\n",
      "COCDA_0076: 2012-05-02 07:08:05 -> 2012-06-01 23:57:11\n",
      "  Flybys inside COCDA_0076: E19 (2012-05-02 18:12:00)\n",
      "\n",
      "COCDA_0094: 2015-10-03 00:02:49 -> 2016-01-01 00:00:44\n",
      "  Flybys inside COCDA_0094: E21 (2015-10-28 15:22:00)\n"
     ]
    }
   ],
   "source": [
    "# check if we downloaded the correct databases\n",
    "\n",
    "flybys = [(n, pd.Timestamp(t)) for n, t in flybys]\n",
    "\n",
    "root = Path(\"../Dataset\")\n",
    "vol_pattern = re.compile(r\"COCDA_\\d{4}\")\n",
    "volumes = [d for d in root.iterdir() if d.is_dir() and vol_pattern.fullmatch(d.name)]\n",
    "\n",
    "for vol in sorted(volumes):\n",
    "    event_files = sorted(vol.glob(\"DATA/**/CDAEVENTS_*.TAB\"))\n",
    "\n",
    "    min_t, max_t = None, None\n",
    "    for f in event_files:\n",
    "        try:\n",
    "            # Read the time\n",
    "            df = pd.read_fwf(f, colspecs=[(11, 28)], names=[\"EVENT_TIME\"], dtype=str)\n",
    "            df[\"EVENT_TIME\"] = pd.to_datetime(df[\"EVENT_TIME\"], errors=\"coerce\", format=\"%Y-%jT%H:%M:%S\")\n",
    "            df = df.dropna(subset=[\"EVENT_TIME\"])\n",
    "\n",
    "            # determine min and maxima\n",
    "            local_min = df[\"EVENT_TIME\"].min()\n",
    "            local_max = df[\"EVENT_TIME\"].max()\n",
    "            if not min_t or local_min < min_t:\n",
    "                min_t = local_min\n",
    "            if not max_t or local_max > max_t:\n",
    "                max_t = local_max\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed parsing {f.name}: {e}\")\n",
    "\n",
    "    if not min_t or not max_t:\n",
    "        print(f\"[INFO] {vol.name}: Could not determine time range\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n{vol.name}: {min_t:%Y-%m-%d %H:%M:%S} -> {max_t:%Y-%m-%d %H:%M:%S}\")\n",
    "\n",
    "    # Check which flybys are in this range\n",
    "    inside = [f\"{n} ({t:%Y-%m-%d %H:%M:%S})\" for n, t in flybys if min_t <= t <= max_t]\n",
    "    if inside:\n",
    "        print(f\"  Flybys inside {vol.name}: {', '.join(inside)}\")\n",
    "    else:\n",
    "        print(f\"  No flybys inside {vol.name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff534e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 54424 rows for E3 from c:\\Users\\jerem\\Desktop\\00FinalProjectWrapper\\DataSet\\cassini_high_rate_detector\\data_science\\raw\\2008\\hrd_2008_070_079.tab\n",
      "Flyby E4: No suitable file found for year 2008 DOY 224\n",
      "Loaded 107757 rows for E5 from c:\\Users\\jerem\\Desktop\\00FinalProjectWrapper\\DataSet\\cassini_high_rate_detector\\data_science\\raw\\2008\\hrd_2008_280_289.tab\n",
      "Loaded 327165 rows for E6 from c:\\Users\\jerem\\Desktop\\00FinalProjectWrapper\\DataSet\\cassini_high_rate_detector\\data_science\\raw\\2008\\hrd_2008_300_309.tab\n",
      "Loaded 3208 rows for E7 from c:\\Users\\jerem\\Desktop\\00FinalProjectWrapper\\DataSet\\cassini_high_rate_detector\\data_science\\raw\\2009\\hrd_2009_300_309.tab\n",
      "Loaded 17 rows for E9 from c:\\Users\\jerem\\Desktop\\00FinalProjectWrapper\\DataSet\\cassini_high_rate_detector\\data_science\\raw\\2010\\hrd_2010_110_119.tab\n",
      "Loaded 3152 rows for E12 from c:\\Users\\jerem\\Desktop\\00FinalProjectWrapper\\DataSet\\cassini_high_rate_detector\\data_science\\raw\\2010\\hrd_2010_330_339.tab\n",
      "Loaded 1779 rows for E13 from c:\\Users\\jerem\\Desktop\\00FinalProjectWrapper\\DataSet\\cassini_high_rate_detector\\data_science\\raw\\2010\\hrd_2010_350_365.tab\n",
      "Loaded 34796 rows for E14 from c:\\Users\\jerem\\Desktop\\00FinalProjectWrapper\\DataSet\\cassini_high_rate_detector\\data_science\\raw\\2011\\hrd_2011_270_279.tab\n",
      "Loaded 1125 rows for E17 from c:\\Users\\jerem\\Desktop\\00FinalProjectWrapper\\DataSet\\cassini_high_rate_detector\\data_science\\raw\\2012\\hrd_2012_080_089.tab\n",
      "Loaded 192 rows for E18 from c:\\Users\\jerem\\Desktop\\00FinalProjectWrapper\\DataSet\\cassini_high_rate_detector\\data_science\\raw\\2012\\hrd_2012_100_109.tab\n",
      "Loaded 2252 rows for E19 from c:\\Users\\jerem\\Desktop\\00FinalProjectWrapper\\DataSet\\cassini_high_rate_detector\\data_science\\raw\\2012\\hrd_2012_120_129.tab\n",
      "Loaded 2601 rows for E21 from c:\\Users\\jerem\\Desktop\\00FinalProjectWrapper\\DataSet\\cassini_high_rate_detector\\data_science\\raw\\2015\\2015_hrd_300_309.tab\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# List of flybys: (name, UTC event time string)\n",
    "flybys = [\n",
    "    (\"E3\",  \"2008-03-12 19:06:45\"), #Confirmed YDong\n",
    "    (\"E4\",  \"2008-08-11 21:06:30\"), # Confirmed\n",
    "    (\"E5\",  \"2008-10-09 19:07:00\"), # Confirmed\n",
    "    (\"E6\",  \"2008-10-31 17:15:30\"), #Confirmed\n",
    "    (\"E7\",  \"2009-11-02 07:42:00\"), #Confirmed\n",
    "    (\"E9\",  \"2010-04-28 00:10:00\"), #Half confirmed\n",
    "    (\"E12\", \"2010-11-30 11:54:00\"), # Half confirmed\n",
    "    (\"E13\", \"2010-12-21 01:08:00\"), #Half confirmed\n",
    "    (\"E14\", \"2011-10-01 13:52:26\"), # Confirmed\n",
    "    (\"E17\", \"2012-03-27 18:30:09\"), # Confirmed\n",
    "    (\"E18\", \"2012-04-14 14:01:30\"), #Confirmed\n",
    "    (\"E19\", \"2012-05-02 09:31:00\"), # Half confirmed\n",
    "    (\"E21\", \"2015-10-28 15:22:42\"), #Half confirmed\n",
    "]\n",
    "\n",
    "# Column names from the label above (28 fields)\n",
    "col_names = [\n",
    "    \"EVENT_CODE\", \"EVC\", \"SYC\", \"TP\", \"STAT\", \"OBS_TIME\", \"SCLK\", \"HD_CLK\", \"CLK\",\n",
    "    \"BIG_M1\", \"BIG_M2\", \"BIG_M3\", \"BIG_M4\", \n",
    "    \"SMALL_M1\", \"SMALL_M2\", \"SMALL_M3\", \"SMALL_M4\",\n",
    "    \"BIG_CM1\", \"BIG_CM2\", \"BIG_CM3\", \"BIG_CM4\",\n",
    "    \"SMALL_CM1\", \"SMALL_CM2\", \"SMALL_CM3\", \"SMALL_CM4\",\n",
    "    \"QUALITY_CODE\", \"THRESHOLD_MASS\", \"THRESHOLD_DIAMETER\",\n",
    "]\n",
    "\n",
    "na_values = {\n",
    "    \"THRESHOLD_MASS\": [\"0.0E+00\"],\n",
    "    \"THRESHOLD_DIAMETER\": [\"-99.9\"],\n",
    "}\n",
    "\n",
    "\n",
    "base_dir = \"../DataSet/cassini_high_rate_detector/data_science/raw\"\n",
    "\n",
    "def load_flyby_events(flybys, base_dir=base_dir):\n",
    "    dfs = {}\n",
    "    for name, utc_str in flybys:\n",
    "        t0 = pd.Timestamp(utc_str)\n",
    "        year = t0.year\n",
    "        doy = t0.dayofyear\n",
    "\n",
    "        subdir = os.path.abspath(os.path.join(base_dir, str(year)))\n",
    "\n",
    "        loaded = False\n",
    "        # Search all .tab files in this year’s folder\n",
    "        for file in os.listdir(subdir):\n",
    "            # Handle both raw (hrd_YYYY_DDD_DDD.tab) and processed (hrd_YYYY_DDD_DDD_prc.tab)\n",
    "            # and also alternative formats like YYYY_hrd_DDD_DDD.tab\n",
    "            match = re.search(r\"(\\d{3})_(\\d{3})(?:_prc)?\\.tab$\", file)\n",
    "            if match and str(year) in file:\n",
    "                start_doy, end_doy = map(int, match.groups())\n",
    "                if start_doy <= doy <= end_doy:\n",
    "                    tab_file = os.path.join(subdir, file)\n",
    "                    df = pd.read_csv(\n",
    "                        tab_file, sep=r'\\s+', names=col_names,\n",
    "                        engine='python', comment='#', skip_blank_lines=True, na_values=na_values,\n",
    "                    )\n",
    "                    df[\"OBS_TIME\"] = pd.to_datetime(df[\"OBS_TIME\"], format=\"%Y-%jT%H:%M:%S.%f\", errors='coerce')\n",
    "                    dfs[name] = df\n",
    "                    print(f\"Loaded {len(df)} rows for {name} from {tab_file}\")\n",
    "                    loaded = True\n",
    "                    break\n",
    "        if not loaded:\n",
    "            print(f\"Flyby {name}: No suitable file found for year {year} DOY {doy}\")\n",
    "    return dfs\n",
    "\n",
    "# Usage:\n",
    "flyby_dfs = load_flyby_events(flybys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d61a3bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E3: 0 events within ±60s of 2008-03-12 19:06:45\n",
      "E4: no data loaded\n",
      "E5: 0 events within ±60s of 2008-10-09 19:07:00\n",
      "E6: 0 events within ±60s of 2008-10-31 17:15:30\n",
      "E7: 976 events within ±60s of 2009-11-02 07:42:00\n",
      "E9: 0 events within ±60s of 2010-04-28 00:10:16\n",
      "E12: 0 events within ±60s of 2010-11-30 11:54:00\n",
      "E13: 143 events within ±60s of 2010-12-21 01:08:00\n",
      "E14: 2182 events within ±60s of 2011-10-01 13:52:26\n",
      "E17: 0 events within ±60s of 2012-03-27 18:30:09\n",
      "E18: 0 events within ±60s of 2012-04-14 14:01:30\n",
      "E19: 0 events within ±60s of 2012-05-02 09:31:00\n",
      "E21: 0 events within ±60s of 2015-10-28 15:22:42\n",
      "   Flyby  Count_±60s\n",
      "0     E3           0\n",
      "1     E5           0\n",
      "2     E6           0\n",
      "3     E7         976\n",
      "4     E9           0\n",
      "5    E12           0\n",
      "6    E13         143\n",
      "7    E14        2182\n",
      "8    E17           0\n",
      "9    E18           0\n",
      "10   E19           0\n",
      "11   E21           0\n"
     ]
    }
   ],
   "source": [
    "# Assume flyby_dfs is the dict of single-flyby DataFrames loaded by previous code\n",
    "all_events = []\n",
    "flyby_window_counts = {}\n",
    "\n",
    "for name, t_peak_str in flybys:\n",
    "    if name not in flyby_dfs:\n",
    "        print(f\"{name}: no data loaded\")\n",
    "        continue\n",
    "\n",
    "    df = flyby_dfs[name].copy()\n",
    "    t_peak = pd.Timestamp(t_peak_str)\n",
    "    # Calculate time difference in seconds relative to plume peak\n",
    "    df[\"DT_PEAK_SEC\"] = (df[\"OBS_TIME\"] - t_peak).dt.total_seconds()\n",
    "    window_mask = df[\"DT_PEAK_SEC\"].abs() <= 60  # ±5 minutes (300 s)\n",
    "    n_pts = window_mask.sum()\n",
    "    flyby_window_counts[name] = n_pts\n",
    "    print(f\"{name}: {n_pts} events within ±60s of {t_peak_str}\")\n",
    "    # Optionally store only those points if you want to concatenate\n",
    "    df_win = df[window_mask].copy()\n",
    "    df_win[\"FLYBY\"] = name\n",
    "    all_events.append(df_win)\n",
    "\n",
    "# If you want to concatenate all selected events into one DataFrame:\n",
    "all_plume_events = pd.concat(all_events, ignore_index=True)\n",
    "\n",
    "# Optionally see the counts as a summary DataFrame:\n",
    "summary = pd.DataFrame(list(flyby_window_counts.items()), columns=[\"Flyby\", \"Count_±60s\"])\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f7a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
